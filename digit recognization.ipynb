{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand written recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# The data that we are interested in is made of 8x8 images of digits, let's\n",
    "# have a look at the first 4 images, stored in the `images` attribute of the\n",
    "# dataset.  If we were working from image files, we could load them using\n",
    "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
    "# images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset.\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(gamma=0.001)\n",
    "\n",
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(data[:n_samples // 2], digits.target[:n_samples // 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        88\n",
      "           1       0.99      0.97      0.98        91\n",
      "           2       0.99      0.99      0.99        86\n",
      "           3       0.98      0.87      0.92        91\n",
      "           4       0.99      0.96      0.97        92\n",
      "           5       0.95      0.97      0.96        91\n",
      "           6       0.99      0.99      0.99        91\n",
      "           7       0.96      0.99      0.97        89\n",
      "           8       0.94      1.00      0.97        88\n",
      "           9       0.93      0.98      0.95        92\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       899\n",
      "   macro avg       0.97      0.97      0.97       899\n",
      "weighted avg       0.97      0.97      0.97       899\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[87  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 88  1  0  0  0  0  0  1  1]\n",
      " [ 0  0 85  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 79  0  3  0  4  5  0]\n",
      " [ 0  0  0  0 88  0  0  0  0  4]\n",
      " [ 0  0  0  0  0 88  1  0  0  2]\n",
      " [ 0  1  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 88  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 88  0]\n",
      " [ 0  0  0  1  0  1  0  0  0 90]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now predict the value of the digit on the second half:\n",
    "expected = digits.target[n_samples // 2:]\n",
    "predicted = classifier.predict(data[n_samples // 2:])\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "\n",
    "images_and_predictions = list(zip(digits.images[n_samples // 2:], predicted))\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[:4]):\n",
    "    plt.subplot(2, 4, index + 5)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Prediction: %i' % prediction)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
